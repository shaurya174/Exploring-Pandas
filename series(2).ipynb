{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "In this notebook , we will explore some of the additional and important opeartions that you can do with series in Pandas.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-2-7dd3504c366f>:1: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "car_prices = {\"Verna\":11,\"Ciaz\":12,\"Virtus\":13}\nreq_series = pd.Series(car_prices)\nreq_series",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Verna     11\nCiaz      12\nVirtus    13\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "We can access specific values using iloc attribute. (Takes Position As Parameter) e.g -> If you want to access 2nd entry here is how you can do it.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "req_series.iloc[1]",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "12"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "If you want to see the price of a specific car means key to access value you use loc attribute.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "req_series.loc[\"Virtus\"]",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "13"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "raw",
      "source": "Pandas tries to make our code a bit more readable and provides a sort of smart syntax using the indexing operator directly on the series itself. For instance, if you pass in an integer parameter, the operator will behave as if you want to query via the Iloc attribute, so will do s sub 3",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "req_series[0] #Deprecated",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-10-b2089155ba5e>:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  req_series[0] #Deprecated\n",
          "output_type": "stream"
        },
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "11"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": "#If we pass object it will query it as if you want to use loc attribute\nreq_series[\"Ciaz\"]",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "12"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": "So what happens if your index is actually a list of integers? And this is a bit complicated and Pandas can't determine automatically whether you're intending to query by index position or index label. So you need to be careful when you're using the indexing operator on the Series itself. The safer option is to be more explicit and to use the iloc and loc attributes directly.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "room_no = {313:\"AIML\",123:\"CSE\",67:\"ECE\"}\nclasses_room_no = pd.Series(room_no)\nclasses_room_no",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "313    AIML\n123     CSE\n67      ECE\ndtype: object"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": "#We get a key error if we use indexing opertor directly so you should use iloc.\nclasses_room_no[0]",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'KeyError'>",
          "evalue": "0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#We get a key error if we use indexing opertor directly so you should use iloc.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mclasses_room_no\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/core/series.py:1111\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/core/series.py:1227\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1227\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3807\u001b[0m     ):\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": "#Let's Talk About Working With Data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Let's talk about calculating average grades\ngrades = pd.Series([90,80,70,60])\nprint(len(grades))\ntotal = 0\nfor i in grades:\n    total = total + i\ntotal/4",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "4\n",
          "output_type": "stream"
        },
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "75.0"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "Pandas and Numpy support a method of computation called vectorization.It work with most of functions including sum function.Let's find total grades",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nprint(np.sum(grades))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "300\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "nums = pd.Series(np.random.randint(0,100,2))\nnums.head()#Look at first values",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0    30\n1    82\ndtype: int32"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": "Vectorization is much faster.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "nums.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0    30\n1    82\ndtype: int32"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": "#Now Let's apply operations\nnums-=4\nnums.head()\n    ",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0    26\n1    78\ndtype: int32"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": "\nnew_nums = pd.Series(np.random.randint(1,1000,1))\nnew_nums.head()\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0    688\ndtype: int32"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": "%%timeit -n 100\ntotal = 0\nfor i in new_nums:\n    i+=2",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "9 µs ± 1.51 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": "One last note on using the indexing operators to access series data. The .loc attribute lets you not only modify data in place, but also add new data as well. If the value you passed in as the index doesn't exist, then a new entry is created. And keep in mind indices can have mixed types. While it's important to be aware of the typing going on underneath, Pandas will automatically change the underlying NumPy types as appropriate.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "user={\"Airtel\":100,\"Jio\":120,\"BSNL\":80}\nusers = pd.Series(users)\n#Add new\nusers",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 38,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0           20\n1           30\n2           40\nHello       80\nVodafone    50\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 38
    },
    {
      "cell_type": "code",
      "source": "#Let's create another Series and merge it with users using pd.concat function\nnew_user = {\"VI\":90,\"MTNL\":95}\nnew_users = pd.Series(new_user)\ntotal_users = pd.concat([new_users,users])\ntotal_users",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 39,
          "output_type": "execute_result",
          "data": {
            "text/plain": "VI          90\nMTNL        95\n0           20\n1           30\n2           40\nHello       80\nVodafone    50\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 39
    },
    {
      "cell_type": "code",
      "source": "#END OF SERIES -> LOOK AT DATAFRAME NEXT",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 40
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}